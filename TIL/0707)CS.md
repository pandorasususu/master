# 2022.07.07

## CS

[[10분 테코톡]파피의 Caching(캐싱)](https://www.youtube.com/watch?v=JBFT4KyEvoY)

**정의**

**캐싱**은 캐시에 데이터나 계산된 결과 값의 복사본을 저장해 둠으로써 전체적인 처리 속도 향상시킴
ex) 데이터에 직접 접근시 오랜 시간 소요, 필요한 값 얻기 위한 계산 생략, 반복적으로 이미지나 썸네일 등 동일한 결과 돌려줘야 함

```
복사본을 이용하는 것이므로 복사본-원본 일관성을 유의해야
```



**개요**

메모리는 CPU와 달리 성능보다는 저장공간을 늘리는 것에 주력
=> 그러나 메모리와 CPU는 여전히 쌍방교류가 활발함
=> 메모리가 CPU의 처리 속도를 따라가지 못하고 교류 과정에서 병목현상 발생

> 이를 해결하기 위해 메모리와 CPU 사이에 캐시 메모리가 등장



캐시 메모리는 작지만 빠름
=>재사용할 데이터의 복사본을 저장해두고, CPU가 요청하는 데이터를 즉시 전달

메인 메모리 DRAM: 한 셀당 트랜지스터 1개
캐시 메모리 SRAM: 한 셀당 트렌지스터 6개, 물리적 크기도 큼 
=> 캐시 메모리는 메인 메모리보다 더 비싸기 때문에, 메인 메모리를 대체하기에 현실적이지 않음

```
실행 속도, 가격
CPU Register > Cache Memory > Main Memory > Secondary Memory
이 메모리 계층 구조 사이에서 또한 캐싱이 일어남
=> 캐싱의 목적은 크고 느린 메모리와 작고 빠른 메모리를 크고 빠른 메모리처럼 작동하게 만드는 것
```



**캐싱 동작 원리**

데이터의 재사용성 판단 기준 => 데이터 지역성의 원리

데이터의 접근이 시공간적으로 가깝게 일어나는 것

=> 한 번 참조된 변수는 재차 참조될 가능성이 높다(시간 지역성) 
==> 메모리 상 같은 주소를 여러번 참조할 경우 상대적으로 작은 크기 캐시 사용해도 효율성 높일 수 있음

=> 어떤 데이터에 접근할 때 그 주위 데이터도 참조될 가능성 높음(공간 지역성)
==> 한 메모리 주소에 접근 시 주소를 포함하는 블록 전부 캐시에 가져옴
==> 이 때 메모리 주소를 오름/내림차순으로 접근하면, 캐시를 통해 접근하게 되므로 캐시 효율성 향상

```java
//ex
for(i=0;i<3;i++){
	data[i+1] = data[i]+1;
}
//변수 i를 선언 후 재접근: 시간 지역성
//data에 순서대로 접근: 공간 지역성
```



cpu에서 메인 메모리에 접근하기 전에 캐시 메모리에 특정 데이터를 요청하고
=> 캐시 메모리에 없으면 **"캐시 미스"**
=> 캐시 메모리에 있으면 **"캐시 히트"**

캐시 히트 상태에서 데이터 쓰기 동작이 발생하면 두가지 선택지 존재
=> 메인 메모리가 아닌 캐시의 데이터가 업데이트 됨

```
1. Write Through 정책
메인 메모리 바로 업데이트
단순하고 캐시-메인 메모리 일관성 유지할 수 있으나, 업데이트 자주 발생해서 느림

2. Write Back 정책
캐시만 업데이트하다, 업데이트 된 데이터가 캐시에서 빠지게 될 때 메인 메모리 업데이트
속도가 빠르지만 캐시-메인 메모리 값이 다른 경우 발생
=> 데이터 변경 확인 위해 캐시 블록마다 dirty 비트 추가, 변경 시 1로 바꿔줌
=> 1이면 메인 메모리 업데이트
```







